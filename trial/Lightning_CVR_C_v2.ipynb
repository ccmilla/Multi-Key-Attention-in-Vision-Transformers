{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.models.vision_transformer import vit_small_patch16_224\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(31)\n",
    "random.seed(31)\n",
    "np.random.seed(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowsAndCols(image, patch_size):\n",
    "    _, H, W = image.shape\n",
    "    num_patches_y = H // patch_size\n",
    "    num_patches_x = W // patch_size\n",
    "    token_rows, token_cols = [], []\n",
    "    for i in range(num_patches_y):\n",
    "        for j in range(num_patches_x):\n",
    "            center_row = i * patch_size + patch_size / 2\n",
    "            center_col = j * patch_size + patch_size / 2\n",
    "            token_rows.append(center_row)\n",
    "            token_cols.append(center_col)\n",
    "    return np.array(token_rows), np.array(token_cols)\n",
    "\n",
    "def makeMasks(token_rows, token_cols):\n",
    "    num_patches = len(token_rows)\n",
    "    left_mask = np.zeros((num_patches, num_patches))\n",
    "    right_mask = np.zeros((num_patches, num_patches))\n",
    "    up_mask = np.zeros((num_patches, num_patches))\n",
    "    down_mask = np.zeros((num_patches, num_patches))\n",
    "    for i in range(num_patches):\n",
    "        for j in range(num_patches):\n",
    "            if token_cols[i] < token_cols[j]: left_mask[i, j] = 1\n",
    "            if token_cols[i] > token_cols[j]: right_mask[i, j] = 1\n",
    "            if token_rows[i] < token_rows[j]: up_mask[i, j] = 1\n",
    "            if token_rows[i] > token_rows[j]: down_mask[i, j] = 1\n",
    "    identity_mask = np.eye(num_patches)\n",
    "    return left_mask, right_mask, up_mask, down_mask, identity_mask\n",
    "\n",
    "def create_mask_list_for_image(image, patch_size, num_heads, device, dtype):\n",
    "    token_rows, token_cols = getRowsAndCols(image, patch_size)\n",
    "    left_np, right_np, up_np, down_np, identity_np = makeMasks(token_rows, token_cols)\n",
    "    def pad_mask(m): return np.pad(m, ((1,0),(1,0)), mode='constant', constant_values=1)\n",
    "    left_np, right_np, up_np, down_np, identity_np = map(pad_mask, [left_np, right_np, up_np, down_np, identity_np])\n",
    "    def to_mask(m): return torch.tensor(m, device=device, dtype=dtype).unsqueeze(0).unsqueeze(0)\n",
    "    left_mask, right_mask, up_mask, down_mask, identity_mask = map(to_mask, [left_np, right_np, up_np, down_np, identity_np])\n",
    "    N = left_mask.shape[-1]\n",
    "    masks = [m.expand(1, num_heads, N, N) for m in [left_mask, right_mask, up_mask, down_mask, identity_mask]]\n",
    "    return tuple(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnTheFlyMaskedFood101(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, transform, patch_size, download=True):\n",
    "        self.dataset = torchvision.datasets.Food101(root=root, split=split, transform=transform, download=download)\n",
    "        self.patch_size = patch_size\n",
    "        #self.num_heads = None\n",
    "        self.dtype = torch.float32\n",
    "        self.device = torch.device(\"cpu\")  # mask creation is light-weight\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        mask_list = create_mask_list_for_image(image, self.patch_size, self.num_heads, device=self.device, dtype=self.dtype)\n",
    "        return image, label, mask_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAttentionMultipleFiveSpatial(nn.Module):\n",
    "    def __init__(self, orig_attn: nn.Module, patch_size=16, img_size=224):\n",
    "        super().__init__()\n",
    "        self.num_heads = orig_attn.num_heads\n",
    "        self.embed_dim = orig_attn.qkv.in_features\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.scale = 1.0 / math.sqrt(self.head_dim)\n",
    "\n",
    "        self.q_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.v_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.kA_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.kB_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.kC_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.kD_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.kE_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.proj = orig_attn.proj\n",
    "\n",
    "        qkv_weight = orig_attn.qkv.weight.clone()\n",
    "        qkv_bias = orig_attn.qkv.bias.clone()\n",
    "        self.q_linear.weight.data.copy_(qkv_weight[:self.embed_dim, :])\n",
    "        for k_lin in [self.kA_linear, self.kB_linear, self.kC_linear, self.kD_linear, self.kE_linear]:\n",
    "            k_lin.weight.data.copy_(qkv_weight[self.embed_dim:2*self.embed_dim, :])\n",
    "        self.v_linear.weight.data.copy_(qkv_weight[2*self.embed_dim:, :])\n",
    "        if qkv_bias is not None:\n",
    "            self.q_linear.bias.data.copy_(qkv_bias[:self.embed_dim])\n",
    "            for k_lin in [self.kA_linear, self.kB_linear, self.kC_linear, self.kD_linear, self.kE_linear]:\n",
    "                k_lin.bias.data.copy_(qkv_bias[self.embed_dim:2*self.embed_dim])\n",
    "            self.v_linear.bias.data.copy_(qkv_bias[2*self.embed_dim:])\n",
    "\n",
    "    def forward(self, query, attn_mask=None):\n",
    "        if not hasattr(self, \"current_mask_list\"):\n",
    "            raise ValueError(\"current_mask_list attribute not set in CustomAttentionMultipleFiveSpatial!\")\n",
    "        left_mask, right_mask, up_mask, down_mask, identity_mask = self.current_mask_list\n",
    "        B, N, _ = query.shape\n",
    "        q = self.q_linear(query).reshape(B, N, self.num_heads, -1).transpose(1, 2) * self.scale\n",
    "        v = self.v_linear(query).reshape(B, N, self.num_heads, -1).transpose(1, 2)\n",
    "        ks = [self.kA_linear, self.kB_linear, self.kC_linear, self.kD_linear, self.kE_linear]\n",
    "        masks = [left_mask, right_mask, up_mask, down_mask, identity_mask]\n",
    "        out = sum((q @ k(query).reshape(B, N, self.num_heads, -1).transpose(1, 2).transpose(-2, -1)).softmax(-1) * m @ v for k, m in zip(ks, masks))\n",
    "        if left_mask.shape[1] != self.num_heads:\n",
    "            left_mask = left_mask[:, :self.num_heads, :, :]\n",
    "            right_mask = right_mask[:, :self.num_heads, :, :]\n",
    "            up_mask = up_mask[:, :self.num_heads, :, :]\n",
    "            down_mask = down_mask[:, :self.num_heads, :, :]\n",
    "            identity_mask = identity_mask[:, :self.num_heads, :, :]\n",
    "\n",
    "        return self.proj(out.transpose(1, 2).reshape(B, N, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTCustom(nn.Module):\n",
    "    def __init__(self, num_blocks_to_keep, patch_size=16, img_size=224):\n",
    "        super().__init__()\n",
    "        full_model = vit_small_patch16_224(pretrained=False, num_classes=101, drop_rate=0.3, drop_path_rate=0.1)\n",
    "        self.patch_embed = full_model.patch_embed\n",
    "        self.cls_token = full_model.cls_token\n",
    "        self.pos_embed = full_model.pos_embed\n",
    "        self.pos_drop = full_model.pos_drop\n",
    "        self.blocks = nn.Sequential()\n",
    "        for i, block in enumerate(full_model.blocks[:num_blocks_to_keep]):\n",
    "            block.attn = CustomAttentionMultipleFiveSpatial(block.attn, patch_size=patch_size, img_size=img_size)\n",
    "            print(f\"Injected custom attention in block {i}\")\n",
    "            self.blocks.append(block)\n",
    "        self.norm = full_model.norm\n",
    "        self.head = full_model.head\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = self.pos_drop(x + self.pos_embed)\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        return self.head(x[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food101DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, patch_size=16):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_size = patch_size\n",
    "        #self.num_heads = num_heads # removed handled in LightningModule\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = OnTheFlyMaskedFood101(\"./data\", \"train\", train_transform, self.patch_size)\n",
    "        self.val_dataset = OnTheFlyMaskedFood101(\"./data\", \"test\", val_transform, self.patch_size)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        #return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, persistent_workers=True) \n",
    "        #same issue with pyTorch - looks like a bug in Jupyter\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=0, persistent_workers=False)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        #return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "        #same issue with pyTorch - looks like a bug in Jupyter\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=True, num_workers=0, persistent_workers=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitViT(pl.LightningModule):\n",
    "    def __init__(self, num_blocks_to_keep=10, patch_size=16, img_size=224, num_classes=101,\n",
    "                 base_lr=1e-5, peak_lr=1e-4, final_lr_frac=0.1, warmup_epochs=15,\n",
    "                 rampup_epochs=15, num_epochs=60, weight_decay=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = ViTCustom(num_blocks_to_keep, patch_size, img_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        print(f\"\\nStarting epoch {self.current_epoch + 1}/{self.hparams.num_epochs}\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        print(f\"Epoch {self.current_epoch + 1} completed in {time.time() - self.epoch_start_time:.2f} sec\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        batch_masks = tuple(m.squeeze(1) for m in masks)\n",
    "        for blk in self.model.blocks:\n",
    "            blk.attn.current_mask_list = batch_masks\n",
    "        out = self(x)\n",
    "        loss = self.criterion(out, y)\n",
    "        acc = (torch.argmax(out, dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        batch_masks = tuple(m.squeeze(1) for m in masks)\n",
    "        for blk in self.model.blocks:\n",
    "            blk.attn.current_mask_list = batch_masks\n",
    "        out = self(x)\n",
    "        loss = self.criterion(out, y)\n",
    "        acc = (torch.argmax(out, dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.base_lr, weight_decay=self.hparams.weight_decay)\n",
    "        def lr_lambda(step):\n",
    "            total_steps = self.trainer.estimated_stepping_batches\n",
    "            warmup_steps = total_steps * self.hparams.warmup_epochs / self.hparams.num_epochs\n",
    "            rampup_steps = total_steps * self.hparams.rampup_epochs / self.hparams.num_epochs\n",
    "            decay_steps = total_steps - warmup_steps - rampup_steps\n",
    "            if step < warmup_steps:\n",
    "                return 1.0\n",
    "            elif step < warmup_steps + rampup_steps:\n",
    "                progress = (step - warmup_steps) / rampup_steps\n",
    "                scaled_lr = self.hparams.base_lr + progress * (self.hparams.peak_lr - self.hparams.base_lr)\n",
    "                return scaled_lr / self.hparams.base_lr\n",
    "            else:\n",
    "                progress = (step - warmup_steps - rampup_steps) / max(1, decay_steps)\n",
    "                cosine = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "                scaled_lr = self.hparams.final_lr_frac * self.hparams.peak_lr + (1 - self.hparams.final_lr_frac) * self.hparams.peak_lr * cosine\n",
    "                return scaled_lr / self.hparams.base_lr\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected custom attention in block 0\n",
      "Injected custom attention in block 1\n",
      "Injected custom attention in block 2\n",
      "Injected custom attention in block 3\n",
      "Injected custom attention in block 4\n",
      "Injected custom attention in block 5\n",
      "Injected custom attention in block 6\n",
      "Injected custom attention in block 7\n",
      "Injected custom attention in block 8\n",
      "Injected custom attention in block 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "c:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=27` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ViTCustom        | 24.1 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "24.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.1 M    Total params\n",
      "96.277    Total estimated model params size (MB)\n",
      "239       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698f4898571c47229658a1cd2b05edcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:484: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=27` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OnTheFlyMaskedFood101' object has no attribute 'num_heads'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m\n\u001b[0;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     20\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[0;32m     21\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Best model saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:560\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:49\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     52\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:598\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    591\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    592\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    594\u001b[0m     ckpt_path,\n\u001b[0;32m    595\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m )\n\u001b[1;32m--> 598\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1011\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m-> 1011\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1053\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1082\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1079\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1082\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:138\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:134\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:61\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\MILLAC24\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mOnTheFlyMaskedFood101.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     10\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx]\n\u001b[1;32m---> 11\u001b[0m     mask_list \u001b[38;5;241m=\u001b[39m create_mask_list_for_image(image, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image, label, mask_list\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OnTheFlyMaskedFood101' object has no attribute 'num_heads'"
     ]
    }
   ],
   "source": [
    "# DataModule\n",
    "data_module = Food101DataModule(batch_size=32, patch_size=16)\n",
    "\n",
    "# Model\n",
    "lit_model = LitViT(num_blocks_to_keep=10, patch_size=16, img_size=224)\n",
    "\n",
    "# TensorBoard Logger\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"food101_experiment\")\n",
    "\n",
    "# ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    filename=\"best-vit-{epoch:02d}-{val_acc:.4f}\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=60,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(lit_model, datamodule=data_module)\n",
    "\n",
    "print(f\"✅ Best model saved at: {checkpoint_callback.best_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
